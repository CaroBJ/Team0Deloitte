{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Imports\n",
    "import random\n",
    "random.seed(10)\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## DataLoader\n",
    "class CarSegData(Dataset):\n",
    "    def __init__(self, data_root, transform=None):\n",
    "        self.data_root = data_root\n",
    "        self.transform = transform\n",
    "        self.class_labels = {\n",
    "            10: 1,\n",
    "            20: 2,\n",
    "            30: 3,\n",
    "            40: 4,\n",
    "            50: 5,\n",
    "            60: 6,\n",
    "            70: 7,\n",
    "            80: 8,\n",
    "            90: 0\n",
    "        }\n",
    "        self.classes = {\n",
    "            1: \"hood\",\n",
    "            2: \"front door\",\n",
    "            3: \"rear door\",\n",
    "            4: \"frame\",\n",
    "            5: \"rear quarter panel\",\n",
    "            6: \"trunk lid\",\n",
    "            7: \"fender\",\n",
    "            8: \"bumper\",\n",
    "            9: \"rest of car\"\n",
    "        }\n",
    "\n",
    "        # List all the array files in the 'arrays' directory\n",
    "        self.array_files = np.load(data_root)\n",
    "\n",
    "    def __len__(self):\n",
    "        return np.shape(self.array_files)[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        array_data = self.array_files[idx,:,:,:]\n",
    "        image_data = array_data[:,:,:3]\n",
    "        target_data = array_data[:,:,3]\n",
    "\n",
    "        # Convert target data to class labels\n",
    "        target_data = self.map_to_class_labels(target_data)\n",
    "        target_data = self.map_to_classes(target_data)\n",
    "\n",
    "        # Convert to PIL image\n",
    "        image = Image.fromarray(image_data.astype('uint8'))\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, target_data\n",
    "\n",
    "    def map_to_classes(self, target_data):\n",
    "        class_labels = np.zeros_like(target_data)\n",
    "        for class_value, class_name in self.classes.items():\n",
    "            class_labels[target_data == class_value] = class_value\n",
    "        return torch.from_numpy(class_labels)\n",
    "    \n",
    "    def map_to_class_labels(self, target_data):\n",
    "        class_labels = np.zeros_like(target_data)\n",
    "        for old_label, new_label in self.class_labels.items():\n",
    "            class_labels[target_data == old_label] = new_label\n",
    "        return torch.from_numpy(class_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unet \n",
    "class DoubleConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(DoubleConv, self).__init__()\n",
    "        self.double_conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout2d(),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout2d()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.double_conv(x)\n",
    "\n",
    "class UNet_new(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(UNet_new, self).__init__()\n",
    "\n",
    "        # Encoder (contracting path)\n",
    "        self.enc1 = DoubleConv(in_channels, 64)\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.enc2 = DoubleConv(64, 128)\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.enc3 = DoubleConv(128, 256)\n",
    "        self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.enc4 = DoubleConv(256, 512)\n",
    "        self.pool4 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        # Middle layer\n",
    "        self.middle = DoubleConv(512, 1024)\n",
    "#         self.dropout = nn.Dropout2d(p=0.5)\n",
    "\n",
    "        # Decoder (expansive path)\n",
    "        self.up1 = nn.ConvTranspose2d(1024, 512, kernel_size=2, stride=2)\n",
    "        self.dec1 = DoubleConv(1024, 512)\n",
    "        self.up2 = nn.ConvTranspose2d(512, 256, kernel_size=2, stride=2)\n",
    "        self.dec2 = DoubleConv(512, 256)\n",
    "        self.up3 = nn.ConvTranspose2d(256, 128, kernel_size=2, stride=2)\n",
    "        self.dec3 = DoubleConv(256, 128)\n",
    "        self.up4 = nn.ConvTranspose2d(128, 64, kernel_size=2, stride=2)\n",
    "        self.dec4 = DoubleConv(128, 64)\n",
    "        \n",
    "        # Output layer\n",
    "        self.out = nn.Conv2d(64, out_channels, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Encoder\n",
    "        enc1 = self.enc1(x)\n",
    "        pool1 = self.pool1(enc1)\n",
    "        enc2 = self.enc2(pool1)\n",
    "        pool2 = self.pool2(enc2)\n",
    "        enc3 = self.enc3(pool2)\n",
    "        pool3 = self.pool3(enc3)\n",
    "        enc4 = self.enc4(pool3)\n",
    "        pool4 = self.pool4(enc4)\n",
    "\n",
    "        # Middle layer\n",
    "        middle = self.middle(pool4)\n",
    "#         middle = self.dropout(middle)\n",
    "\n",
    "        # Decoder with skip connections\n",
    "        up1 = self.up1(middle)\n",
    "        concat1 = torch.cat((up1, enc4), dim=1)\n",
    "        dec1 = self.dec1(concat1)\n",
    "        up2 = self.up2(dec1)\n",
    "        concat2 = torch.cat((up2, enc3), dim=1)\n",
    "        dec2 = self.dec2(concat2)\n",
    "        up3 = self.up3(dec2)\n",
    "        concat3 = torch.cat((up3, enc2), dim=1)\n",
    "        dec3 = self.dec3(concat3)\n",
    "        up4 = self.up4(dec3)\n",
    "        concat4 = torch.cat((up4, enc1), dim=1)\n",
    "        dec4 = self.dec4(concat4)\n",
    "        \n",
    "        # Output layer\n",
    "        out = self.out(dec4)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TRAINING\n",
    "# Move the model and data to the GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# device = torch.device(\"cpu\")\n",
    "print(f'Training on {device}')\n",
    "# Define the input and output channels\n",
    "in_channels = 3  # Input channels (RGB)\n",
    "out_channels = 9  # Number of classes\n",
    "\n",
    "# Create the U-Net model\n",
    "model = UNet_new(in_channels, out_channels)\n",
    "model.to(device)\n",
    "\n",
    "# path to data\n",
    "path = '/scratch/s204254/CarSegData/carseg_data_new_new/only_real.npy'\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor()# Converts the image to a tensor\n",
    "])\n",
    "\n",
    "\n",
    "dataset = CarSegData(data_root=path,transform=transform)\n",
    "train_set, val_set = torch.utils.data.random_split(dataset, [130, 8])\n",
    "\n",
    "\n",
    "# Define batch size and other DataLoader parameters\n",
    "batch_size = 32\n",
    "num_workers = 2\n",
    "learning_rate = 0.001\n",
    "num_epochs = 2000\n",
    "wd = 1e-4\n",
    "dropout = 0.5\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate,weight_decay = wd)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Create the data loader\n",
    "train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
    "print(f\"Number of batches in training set: {len(train_loader)}\")\n",
    "val_loader = DataLoader(val_set, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
    "print(f\"Number of batches in validation set: {len(val_loader)}\")\n",
    "\n",
    "# Training loop\n",
    "print(\"~  B E G I N   T R A I N I N G  ~\\n\")\n",
    "validation_every_number_of_epoch = 1\n",
    "train_loss_all = []\n",
    "val_loss_all = []\n",
    "best_score = 1000000\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    train_loss = []\n",
    "\n",
    "    for i, batch in enumerate(train_loader):\n",
    "        images, labels = batch\n",
    "        images, labels = images.to(device), labels.to(device).type(torch.long)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "\n",
    "        # Compute the loss\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backpropagation and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        train_loss.append(loss.item())\n",
    "    if epoch % validation_every_number_of_epoch == 0:\n",
    "        val_loss = []\n",
    "        with torch.no_grad():\n",
    "            model.eval()\n",
    "            for i, batch in enumerate(val_loader):\n",
    "                images, labels = batch\n",
    "                images, labels = images.to(device), labels.to(device).type(torch.long)\n",
    "\n",
    "                # Forward pass\n",
    "                outputs = model(images)\n",
    "\n",
    "                # Compute the loss\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss.append(loss.item())\n",
    "    model.train()\n",
    "\n",
    "    \n",
    "    sum_loss = np.sum(train_loss)\n",
    "    n_losses = len(train_loss)\n",
    "    print(f\"Epoch {epoch+1} average train loss: {sum_loss/n_losses:.4f}\")\n",
    "    train_loss_all.append(sum_loss/n_losses)\n",
    "    \n",
    "    sum_val_loss = np.sum(val_loss)\n",
    "    n_val_losses = len(val_loss)\n",
    "    print(f\"Epoch {epoch+1} average validation loss: {sum_val_loss/n_val_losses:.4f} \")\n",
    "    val_loss_all.append(sum_val_loss/n_val_losses)\n",
    "print(\" \")    \n",
    "print(\"~ F I N I S H E D   T R A I N I N G ~\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SpineProject",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
