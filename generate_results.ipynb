{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Imports\n",
    "import random\n",
    "random.seed(10)\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms\n",
    "import matplotlib as plt\n",
    "from torchmetrics import JaccardIndex\n",
    "from matplotlib.colors import ListedColormap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## DataLoader\n",
    "class CarSegData(Dataset):\n",
    "    def __init__(self, data_root, transform=None):\n",
    "        self.data_root = data_root\n",
    "        self.transform = transform\n",
    "        self.class_labels = {\n",
    "            10: 1,\n",
    "            20: 2,\n",
    "            30: 3,\n",
    "            40: 4,\n",
    "            50: 5,\n",
    "            60: 6,\n",
    "            70: 7,\n",
    "            80: 8,\n",
    "            90: 0\n",
    "        }\n",
    "        self.classes = {\n",
    "            1: \"hood\",\n",
    "            2: \"front door\",\n",
    "            3: \"rear door\",\n",
    "            4: \"frame\",\n",
    "            5: \"rear quarter panel\",\n",
    "            6: \"trunk lid\",\n",
    "            7: \"fender\",\n",
    "            8: \"bumper\",\n",
    "            9: \"rest of car\"\n",
    "        }\n",
    "\n",
    "        # List all the array files in the 'arrays' directory\n",
    "        self.array_files = np.load(data_root)\n",
    "\n",
    "    def __len__(self):\n",
    "        return np.shape(self.array_files)[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        array_data = self.array_files[idx,:,:,:]\n",
    "        image_data = array_data[:,:,:3]\n",
    "        target_data = array_data[:,:,3]\n",
    "\n",
    "        # Convert target data to class labels\n",
    "        target_data = self.map_to_class_labels(target_data)\n",
    "        target_data = self.map_to_classes(target_data)\n",
    "\n",
    "        # Convert to PIL image\n",
    "        image = Image.fromarray(image_data.astype('uint8'))\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, target_data\n",
    "\n",
    "    def map_to_classes(self, target_data):\n",
    "        class_labels = np.zeros_like(target_data)\n",
    "        for class_value, class_name in self.classes.items():\n",
    "            class_labels[target_data == class_value] = class_value\n",
    "        return torch.from_numpy(class_labels)\n",
    "    \n",
    "    def map_to_class_labels(self, target_data):\n",
    "        class_labels = np.zeros_like(target_data)\n",
    "        for old_label, new_label in self.class_labels.items():\n",
    "            class_labels[target_data == old_label] = new_label\n",
    "        return torch.from_numpy(class_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unet \n",
    "class DoubleConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(DoubleConv, self).__init__()\n",
    "        self.double_conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout2d(),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout2d()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.double_conv(x)\n",
    "\n",
    "class UNet_new(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(UNet_new, self).__init__()\n",
    "\n",
    "        # Encoder (contracting path)\n",
    "        self.enc1 = DoubleConv(in_channels, 64)\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.enc2 = DoubleConv(64, 128)\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.enc3 = DoubleConv(128, 256)\n",
    "        self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.enc4 = DoubleConv(256, 512)\n",
    "        self.pool4 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        # Middle layer\n",
    "        self.middle = DoubleConv(512, 1024)\n",
    "#         self.dropout = nn.Dropout2d(p=0.5)\n",
    "\n",
    "        # Decoder (expansive path)\n",
    "        self.up1 = nn.ConvTranspose2d(1024, 512, kernel_size=2, stride=2)\n",
    "        self.dec1 = DoubleConv(1024, 512)\n",
    "        self.up2 = nn.ConvTranspose2d(512, 256, kernel_size=2, stride=2)\n",
    "        self.dec2 = DoubleConv(512, 256)\n",
    "        self.up3 = nn.ConvTranspose2d(256, 128, kernel_size=2, stride=2)\n",
    "        self.dec3 = DoubleConv(256, 128)\n",
    "        self.up4 = nn.ConvTranspose2d(128, 64, kernel_size=2, stride=2)\n",
    "        self.dec4 = DoubleConv(128, 64)\n",
    "        \n",
    "        # Output layer\n",
    "        self.out = nn.Conv2d(64, out_channels, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Encoder\n",
    "        enc1 = self.enc1(x)\n",
    "        pool1 = self.pool1(enc1)\n",
    "        enc2 = self.enc2(pool1)\n",
    "        pool2 = self.pool2(enc2)\n",
    "        enc3 = self.enc3(pool2)\n",
    "        pool3 = self.pool3(enc3)\n",
    "        enc4 = self.enc4(pool3)\n",
    "        pool4 = self.pool4(enc4)\n",
    "\n",
    "        # Middle layer\n",
    "        middle = self.middle(pool4)\n",
    "#         middle = self.dropout(middle)\n",
    "\n",
    "        # Decoder with skip connections\n",
    "        up1 = self.up1(middle)\n",
    "        concat1 = torch.cat((up1, enc4), dim=1)\n",
    "        dec1 = self.dec1(concat1)\n",
    "        up2 = self.up2(dec1)\n",
    "        concat2 = torch.cat((up2, enc3), dim=1)\n",
    "        dec2 = self.dec2(concat2)\n",
    "        up3 = self.up3(dec2)\n",
    "        concat3 = torch.cat((up3, enc2), dim=1)\n",
    "        dec3 = self.dec3(concat3)\n",
    "        up4 = self.up4(dec3)\n",
    "        concat4 = torch.cat((up4, enc1), dim=1)\n",
    "        dec4 = self.dec4(concat4)\n",
    "        \n",
    "        # Output layer\n",
    "        out = self.out(dec4)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "in_channels = 3  # Input channels (RGB)\n",
    "out_channels = 9  # Number of classes\n",
    "model_only_real = UNet_new(in_channels, out_channels)\n",
    "model_10p_fake = UNet_new(in_channels, out_channels)\n",
    "model_only_real.to(device)\n",
    "model_10p_fake.to(device)\n",
    "\n",
    "# model file root\n",
    "previous_model_file_root = \"data_handin/\" ######### Change this ##########\n",
    "\n",
    "# Name of the models\n",
    "previous_model1 = 'best_model_weights_only_real_data_batch_norm_dropout_no_rest_of_car'\n",
    "previous_model2 = 'best_model_weights_10p_real_val'\n",
    "\n",
    "# Load model weights\n",
    "checkpoint1 = torch.load(f\"{previous_model_file_root}/{previous_model1}\")\n",
    "checkpoint2 = torch.load(f\"{previous_model_file_root}/{previous_model2}\")\n",
    "\n",
    "model_only_real.load_state_dict(checkpoint2['model_state_dict'])\n",
    "model_10p_fake.load_state_dict(checkpoint1['model_state_dict'])\n",
    "\n",
    "# Tranformation to use on the test data\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor()# Converts the image to a tensor\n",
    "])\n",
    "\n",
    "# Load the test data\n",
    "path_test =  'data_handin\\Prossed_data_test_ny.npy' ######### Change this ##########\n",
    "testdata = CarSegData(data_root=path_test,transform=transform)\n",
    "test_loader = DataLoader(testdata, batch_size=1, shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the colormap\n",
    "class_colors = [\"black\",\"orange\", \"darkgreen\", \"yellow\", \"cyan\", \"purple\", \"lightgreen\", \"blue\", \"magenta\"]\n",
    "class_values = [0, 1, 2, 3, 4, 5, 6, 7, 8]\n",
    "cmap = ListedColormap(class_colors, name='custom_colormap', N=len(class_colors))\n",
    "\n",
    "def check_accuracy(loader, model,plot=False): \n",
    "    model.eval()\n",
    "    IoU = []\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x = x.to(device)\n",
    "            y = y.to(device).float()\n",
    "            softmax = nn.Softmax(dim=1)\n",
    "            z = model(x)\n",
    "            preds = torch.argmax(softmax(z),axis=1)\n",
    "            jaccard = JaccardIndex(task='multiclass', num_classes=9,average='macro').to(device)\n",
    "            curr = jaccard(preds,y).item()\n",
    "            IoU.append(curr)\n",
    "            if plot:\n",
    "                fig, (ax1, ax2, ax3) = plt.subplots(1, 3,figsize=(15, 15))\n",
    "                ax1.imshow(x[0,:,:,:].cpu().detach().numpy().transpose(1,2,0))\n",
    "                ax1.set_title('Original image')\n",
    "                ax1.axis('off')\n",
    "                ax2.imshow(y[0,:,:].cpu().detach().numpy(),cmap=cmap)\n",
    "                ax2.set_title('Targets')\n",
    "                ax2.axis('off')\n",
    "                ax3.imshow(preds[0,:,:].cpu().detach().numpy(),cmap = cmap)\n",
    "                ax3.set_title(f'Predictions, IoU: {curr:.3}')\n",
    "                ax3.axis('off')\n",
    "                plt.show()\n",
    "    print(f\"Average IoU score: {np.round(np.sum(IoU)/len(IoU),3)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check accuracy on the test data with Unet model trained on only real data\n",
    "check_accuracy(test_loader, model_only_real,plot=False) # set plot=True to see the predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check accuracy on the test data with Unet model trained on 10% CAD data\n",
    "check_accuracy(test_loader, model_10p_fake,plot=False) # set plot=True to see the predictions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SpineProject",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
