{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-21T14:56:23.015871Z",
     "iopub.status.busy": "2023-12-21T14:56:23.014837Z",
     "iopub.status.idle": "2023-12-21T14:56:23.022344Z",
     "shell.execute_reply": "2023-12-21T14:56:23.021102Z",
     "shell.execute_reply.started": "2023-12-21T14:56:23.015829Z"
    }
   },
   "outputs": [],
   "source": [
    "## Imports\n",
    "import random\n",
    "random.seed(10)\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms\n",
    "import matplotlib.pyplot as plt\n",
    "from torchmetrics import JaccardIndex\n",
    "from matplotlib.colors import ListedColormap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-21T14:48:35.496585Z",
     "iopub.status.busy": "2023-12-21T14:48:35.495255Z",
     "iopub.status.idle": "2023-12-21T14:48:35.509176Z",
     "shell.execute_reply": "2023-12-21T14:48:35.507839Z",
     "shell.execute_reply.started": "2023-12-21T14:48:35.496539Z"
    }
   },
   "outputs": [],
   "source": [
    "## DataLoader\n",
    "class CarSegData(Dataset):\n",
    "    def __init__(self, data_root, transform=None):\n",
    "        self.data_root = data_root\n",
    "        self.transform = transform\n",
    "        self.class_labels = {\n",
    "            10: 1,\n",
    "            20: 2,\n",
    "            30: 3,\n",
    "            40: 4,\n",
    "            50: 5,\n",
    "            60: 6,\n",
    "            70: 7,\n",
    "            80: 8,\n",
    "            90: 0\n",
    "        }\n",
    "        self.classes = {\n",
    "            1: \"hood\",\n",
    "            2: \"front door\",\n",
    "            3: \"rear door\",\n",
    "            4: \"frame\",\n",
    "            5: \"rear quarter panel\",\n",
    "            6: \"trunk lid\",\n",
    "            7: \"fender\",\n",
    "            8: \"bumper\",\n",
    "            9: \"rest of car\"\n",
    "        }\n",
    "\n",
    "        # List all the array files in the 'arrays' directory\n",
    "        self.array_files = np.load(data_root)\n",
    "\n",
    "    def __len__(self):\n",
    "        return np.shape(self.array_files)[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        array_data = self.array_files[idx,:,:,:]\n",
    "        image_data = array_data[:,:,:3]\n",
    "        target_data = array_data[:,:,3]\n",
    "\n",
    "        # Convert target data to class labels\n",
    "        target_data = self.map_to_class_labels(target_data)\n",
    "        target_data = self.map_to_classes(target_data)\n",
    "\n",
    "        # Convert to PIL image\n",
    "        image = Image.fromarray(image_data.astype('uint8'))\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, target_data\n",
    "\n",
    "    def map_to_classes(self, target_data):\n",
    "        class_labels = np.zeros_like(target_data)\n",
    "        for class_value, class_name in self.classes.items():\n",
    "            class_labels[target_data == class_value] = class_value\n",
    "        return torch.from_numpy(class_labels)\n",
    "    \n",
    "    def map_to_class_labels(self, target_data):\n",
    "        class_labels = np.zeros_like(target_data)\n",
    "        for old_label, new_label in self.class_labels.items():\n",
    "            class_labels[target_data == old_label] = new_label\n",
    "        return torch.from_numpy(class_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-21T14:48:36.704024Z",
     "iopub.status.busy": "2023-12-21T14:48:36.703680Z",
     "iopub.status.idle": "2023-12-21T14:48:36.721580Z",
     "shell.execute_reply": "2023-12-21T14:48:36.720459Z",
     "shell.execute_reply.started": "2023-12-21T14:48:36.703998Z"
    }
   },
   "outputs": [],
   "source": [
    "# Unet \n",
    "class DoubleConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(DoubleConv, self).__init__()\n",
    "        self.double_conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout2d(),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout2d()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.double_conv(x)\n",
    "\n",
    "class UNet_new(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(UNet_new, self).__init__()\n",
    "\n",
    "        # Encoder (contracting path)\n",
    "        self.enc1 = DoubleConv(in_channels, 64)\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.enc2 = DoubleConv(64, 128)\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.enc3 = DoubleConv(128, 256)\n",
    "        self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.enc4 = DoubleConv(256, 512)\n",
    "        self.pool4 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        # Middle layer\n",
    "        self.middle = DoubleConv(512, 1024)\n",
    "#         self.dropout = nn.Dropout2d(p=0.5)\n",
    "\n",
    "        # Decoder (expansive path)\n",
    "        self.up1 = nn.ConvTranspose2d(1024, 512, kernel_size=2, stride=2)\n",
    "        self.dec1 = DoubleConv(1024, 512)\n",
    "        self.up2 = nn.ConvTranspose2d(512, 256, kernel_size=2, stride=2)\n",
    "        self.dec2 = DoubleConv(512, 256)\n",
    "        self.up3 = nn.ConvTranspose2d(256, 128, kernel_size=2, stride=2)\n",
    "        self.dec3 = DoubleConv(256, 128)\n",
    "        self.up4 = nn.ConvTranspose2d(128, 64, kernel_size=2, stride=2)\n",
    "        self.dec4 = DoubleConv(128, 64)\n",
    "        \n",
    "        # Output layer\n",
    "        self.out = nn.Conv2d(64, out_channels, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Encoder\n",
    "        enc1 = self.enc1(x)\n",
    "        pool1 = self.pool1(enc1)\n",
    "        enc2 = self.enc2(pool1)\n",
    "        pool2 = self.pool2(enc2)\n",
    "        enc3 = self.enc3(pool2)\n",
    "        pool3 = self.pool3(enc3)\n",
    "        enc4 = self.enc4(pool3)\n",
    "        pool4 = self.pool4(enc4)\n",
    "\n",
    "        # Middle layer\n",
    "        middle = self.middle(pool4)\n",
    "#         middle = self.dropout(middle)\n",
    "\n",
    "        # Decoder with skip connections\n",
    "        up1 = self.up1(middle)\n",
    "        concat1 = torch.cat((up1, enc4), dim=1)\n",
    "        dec1 = self.dec1(concat1)\n",
    "        up2 = self.up2(dec1)\n",
    "        concat2 = torch.cat((up2, enc3), dim=1)\n",
    "        dec2 = self.dec2(concat2)\n",
    "        up3 = self.up3(dec2)\n",
    "        concat3 = torch.cat((up3, enc2), dim=1)\n",
    "        dec3 = self.dec3(concat3)\n",
    "        up4 = self.up4(dec3)\n",
    "        concat4 = torch.cat((up4, enc1), dim=1)\n",
    "        dec4 = self.dec4(concat4)\n",
    "        \n",
    "        # Output layer\n",
    "        out = self.out(dec4)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pix2Pix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-21T14:48:37.415959Z",
     "iopub.status.busy": "2023-12-21T14:48:37.415591Z",
     "iopub.status.idle": "2023-12-21T14:48:37.427509Z",
     "shell.execute_reply": "2023-12-21T14:48:37.426352Z",
     "shell.execute_reply.started": "2023-12-21T14:48:37.415930Z"
    }
   },
   "outputs": [],
   "source": [
    "class EncoderBlock(nn.Module):\n",
    "    \n",
    "    def __init__(self,in_channels, out_channels,device, kernel_size = 4, stride = 2, padding = 1, norm = True):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding, device = device)\n",
    "        self.act = nn.LeakyReLU(0.2, inplace=False) #The choice 0.2 is from the paper\n",
    "        \n",
    "        self.use_norm= norm\n",
    "        if norm:\n",
    "            self.bn = nn.BatchNorm2d(out_channels, device = device)\n",
    "        else:\n",
    "            self.bn = None\n",
    "    def forward(self,x):\n",
    "        x = self.conv(x)\n",
    "        \n",
    "        if self.use_norm:\n",
    "            x = self.bn(x)\n",
    "        x = self.act(x)\n",
    "        return x\n",
    "\n",
    "    \n",
    "class DecoderBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, device,\n",
    "                kernel_size = 4, stride = 2, padding = 1,dropout = False):\n",
    "        super().__init__()\n",
    "        self.conv = nn.ConvTranspose2d(in_channels,out_channels,kernel_size, stride, padding,device = device)\n",
    "    \n",
    "        self.act = nn.ReLU(inplace = False)\n",
    "        self.bn = nn.BatchNorm2d(out_channels, device = device)\n",
    "    \n",
    "\n",
    "        if dropout is not None:\n",
    "            self.dropout = nn.Dropout2d(p = 0.5, inplace = False) # p = 0.5 is from the paper\n",
    "        else:\n",
    "            self.dropout = None\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = self.conv(x)\n",
    "        x = self.bn(x)\n",
    "        x = self.act(x)\n",
    "        \n",
    "        if self.dropout is not None:\n",
    "            x = self.dropout(x)\n",
    "        \n",
    "        return x    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-21T14:48:37.813228Z",
     "iopub.status.busy": "2023-12-21T14:48:37.812842Z",
     "iopub.status.idle": "2023-12-21T14:48:37.828221Z",
     "shell.execute_reply": "2023-12-21T14:48:37.827216Z",
     "shell.execute_reply.started": "2023-12-21T14:48:37.813185Z"
    }
   },
   "outputs": [],
   "source": [
    "#Encoder\n",
    "#C64-C128-C256-C512-C512-C512-C512-C512\n",
    "# 1    2    3    4    5    6   7    8\n",
    "#CD512-CD1024-CD1024-C1024-C1024-C512-C256-C128\n",
    "class UNet_Generator(nn.Module):\n",
    "    def __init__(self,device, input_channels= 3, out_channels = 9):\n",
    "        super().__init__()\n",
    "        #Encoder\n",
    "        self.EB1 = EncoderBlock(input_channels,64,  norm=False, device = device)\n",
    "        self.EB2 = EncoderBlock(64,128, device = device)\n",
    "        self.EB3 = EncoderBlock(128,256, device = device)\n",
    "        self.EB4 = EncoderBlock(256,512, device = device)\n",
    "        self.EB5 = EncoderBlock(512,512, device = device)\n",
    "        self.EB6 = EncoderBlock(512,512, device = device)\n",
    "        self.EB7 = EncoderBlock(512,512, device = device)\n",
    "        self.EB8 = EncoderBlock(512,512, norm = False, device = device)\n",
    "        \n",
    "        #Decoder\n",
    "        self.DB8 = DecoderBlock(512,512,dropout=True, device = device)\n",
    "        self.DB7 = DecoderBlock(2*512,512,dropout=True, device = device)\n",
    "        self.DB6 = DecoderBlock(2*512,512,dropout=True, device = device)\n",
    "        self.DB5 = DecoderBlock(2*512,512,device = device)\n",
    "        self.DB4 = DecoderBlock(2*512,256,device = device)\n",
    "        self.DB3 = DecoderBlock(2*256,128,device = device)\n",
    "        self.DB2 = DecoderBlock(2*128,64,device = device)\n",
    "        self.DB1 = nn.ConvTranspose2d(2*64, out_channels, kernel_size=4, stride=2, padding=1, device= device)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        #Encoder\n",
    "        e1 = self.EB1(x)\n",
    "        e2 = self.EB2(e1)\n",
    "        e3 = self.EB3(e2)\n",
    "        e4 = self.EB4(e3)\n",
    "        e5 = self.EB5(e4)\n",
    "        e6 = self.EB6(e5)\n",
    "        e7 = self.EB7(e6)\n",
    "        e8 = self.EB8(e7)\n",
    "        \n",
    "        #Decoder\n",
    "        s8 = self.DB8(e8)\n",
    "        s7 = self.DB7(torch.cat([s8,e7], dim = 1)) #Add skip connections\n",
    "        s6 = self.DB6(torch.cat([s7,e6], dim = 1)) #Add skip connections\n",
    "        s5 = self.DB5(torch.cat([s6,e5], dim = 1)) #Add skip connections\n",
    "        s4 = self.DB4(torch.cat([s5,e4], dim = 1)) #Add skip connections\n",
    "        s3 = self.DB3(torch.cat([s4,e3], dim = 1)) #Add skip connections\n",
    "        s2 = self.DB2(torch.cat([s3,e2], dim = 1))  #Add skip connections\n",
    "        s1 = self.DB1(torch.cat([s2,e1], dim = 1)) #Add skip connections\n",
    "                \n",
    "        return s1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-21T14:48:38.295521Z",
     "iopub.status.busy": "2023-12-21T14:48:38.294601Z",
     "iopub.status.idle": "2023-12-21T14:48:38.306978Z",
     "shell.execute_reply": "2023-12-21T14:48:38.306057Z",
     "shell.execute_reply.started": "2023-12-21T14:48:38.295482Z"
    }
   },
   "outputs": [],
   "source": [
    "#C64-C128-C256-C512\n",
    "class DiscriminatorBlock(nn.Module):\n",
    "    \n",
    "    def __init__(self,in_channels, out_channels,device, kernel_size = 4, stride = 2, padding = 1, norm = True):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding, device = device)\n",
    "        self.act = nn.LeakyReLU(0.2, inplace=True) #The choice 0.2 is from the paper\n",
    "        \n",
    "        self.use_norm= norm\n",
    "        if norm:\n",
    "            self.bn = nn.BatchNorm2d(out_channels, device = device)\n",
    "        else:\n",
    "            self.bn = None\n",
    "    def forward(self,x):\n",
    "        x = self.conv(x)\n",
    "        if self.use_norm:\n",
    "            x = self.bn(x)\n",
    "        x = self.act(x)\n",
    "        return x\n",
    "        \n",
    "\n",
    "class PatchGan_Discriminator(nn.Module):\n",
    "    def __init__(self, device):\n",
    "        super().__init__()\n",
    "        self.l1 = DiscriminatorBlock(3 + 1,64,norm=False, device= device)\n",
    "        self.l2 = DiscriminatorBlock(64,128, device= device)\n",
    "        self.l3 = DiscriminatorBlock(128,256, device= device)\n",
    "        self.l4 = DiscriminatorBlock(256,512, device= device)\n",
    "        self.l5 = nn.Conv2d(512, 1, kernel_size=4, stride=1, padding=1, device= device)\n",
    "    \n",
    "    def forward(self,mask,image):\n",
    "        #The discrimator is condition on the true image\n",
    "        if mask.shape[1] > 1:\n",
    "            mask = masker(mask)\n",
    "        x = torch.cat([mask,image], dim = 1)\n",
    "        x = self.l1(x)\n",
    "        x = self.l2(x)\n",
    "        x = self.l3(x)\n",
    "        x = self.l4(x)\n",
    "        x = self.l5(x)\n",
    "        # Last output will be a value between 0 and 1\n",
    "        x = torch.sigmoid(x) \n",
    "        return x\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-21T15:00:47.732189Z",
     "iopub.status.busy": "2023-12-21T15:00:47.731268Z",
     "iopub.status.idle": "2023-12-21T15:00:50.083893Z",
     "shell.execute_reply": "2023-12-21T15:00:50.083052Z",
     "shell.execute_reply.started": "2023-12-21T15:00:47.732145Z"
    }
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "in_channels = 3  # Input channels (RGB)\n",
    "out_channels = 9  # Number of classes\n",
    "# Baseline\n",
    "model_only_real = UNet_new(in_channels, out_channels)\n",
    "model_only_real.to(device)\n",
    "#model_10p_fake = UNet_new(in_channels, out_channels)\n",
    "#model_10p_fake.to(device)\n",
    "\n",
    "PATH_baseline = \"/kaggle/input/model-eval/best_model_weights_only_real_data_batch_norm_dropout_no_rest_of_car\"\n",
    "checkpoint1 = torch.load(PATH_baseline)\n",
    "model_only_real.load_state_dict(checkpoint1['model_state_dict'])\n",
    "\n",
    "#Pix2pix\n",
    "PATH_p2p_FL = \"/kaggle/input/model-eval/generator_FL_2000.pt\" #Path to pretrained models\n",
    "g_FL = torch.load(PATH_p2p_FL)\n",
    "\n",
    "PATH_p2p_CE = \"/kaggle/input/model-eval/generator_CE.pt\" #Path to pretrained models\n",
    "g_CE= torch.load(PATH_p2p_CE)\n",
    "\n",
    "# model file root\n",
    "#previous_model_file_root = \"data_handin/\" ######### Change this ##########\n",
    "\n",
    "# Name of the models\n",
    "#previous_model1 = 'best_model_weights_only_real_data_batch_norm_dropout_no_rest_of_car'\n",
    "#previous_model2 = 'best_model_weights_10p_real_val'\n",
    "\n",
    "# Load model weights\n",
    "#checkpoint1 = torch.load(f\"{previous_model_file_root}/{previous_model1}\")\n",
    "#checkpoint2 = torch.load(f\"{previous_model_file_root}/{previous_model2}\")\n",
    "\n",
    "#model_only_real.load_state_dict(checkpoint2['model_state_dict'])\n",
    "#model_10p_fake.load_state_dict(checkpoint1['model_state_dict'])\n",
    "\n",
    "# Tranformation to use on the test data\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor()# Converts the image to a tensor\n",
    "])\n",
    "\n",
    "# Load the test data\n",
    "\"\"\n",
    "path_test =  '/kaggle/input/data-deloitte/Prossed_data_test_ny.npy' ######### Change this ##########\n",
    "testdata = CarSegData(data_root=path_test,transform=transform)\n",
    "test_loader = DataLoader(testdata, batch_size=1, shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-21T14:56:58.270789Z",
     "iopub.status.busy": "2023-12-21T14:56:58.270020Z",
     "iopub.status.idle": "2023-12-21T14:56:58.283113Z",
     "shell.execute_reply": "2023-12-21T14:56:58.282072Z",
     "shell.execute_reply.started": "2023-12-21T14:56:58.270752Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define the colormap\n",
    "class_colors = [\"black\",\"orange\", \"darkgreen\", \"yellow\", \"cyan\", \"purple\", \"lightgreen\", \"blue\", \"magenta\"]\n",
    "class_values = [0, 1, 2, 3, 4, 5, 6, 7, 8]\n",
    "cmap = ListedColormap(class_colors, name='custom_colormap', N=len(class_colors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-21T15:04:16.067978Z",
     "iopub.status.busy": "2023-12-21T15:04:16.067213Z",
     "iopub.status.idle": "2023-12-21T15:04:16.082704Z",
     "shell.execute_reply": "2023-12-21T15:04:16.081693Z",
     "shell.execute_reply.started": "2023-12-21T15:04:16.067939Z"
    }
   },
   "outputs": [],
   "source": [
    "def check_accuracy(loader, baseline, P2P_CE,P2P_FL,plot=False): \n",
    "    baseline.eval()\n",
    "    P2P_CE.eval()\n",
    "    P2P_FL.eval()\n",
    "    IoU_b = []\n",
    "    IoU_CE = []\n",
    "    IoU_FL = []\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x = x.to(device)\n",
    "            y = y.to(device).float()\n",
    "            softmax = nn.Softmax(dim=1)\n",
    "            z_b = baseline(x)\n",
    "            z_CE = P2P_CE(x)\n",
    "            z_FL = P2P_FL(x)\n",
    "            preds_b = torch.argmax(softmax(z_b),axis=1)\n",
    "            preds_CE = torch.argmax(softmax(z_CE),axis=1)\n",
    "            preds_FL = torch.argmax(softmax(z_FL),axis=1)\n",
    "            jaccard = JaccardIndex(task='multiclass', num_classes=9,average='macro').to(device)\n",
    "            curr_b  = jaccard(preds_b,y).item()\n",
    "            curr_CE = jaccard(preds_CE,y).item()\n",
    "            curr_FL = jaccard(preds_FL,y).item()\n",
    "            IoU_b.append(curr_b)\n",
    "            IoU_CE.append(curr_CE)\n",
    "            IoU_FL.append(curr_FL)\n",
    "            if plot:\n",
    "                fig, (ax1, ax2, ax3, ax4, ax5) = plt.subplots(1, 5,figsize=(15, 15))\n",
    "                ax1.imshow(x[0,:,:,:].cpu().detach().numpy().transpose(1,2,0))\n",
    "                ax1.set_title('Original image')\n",
    "                ax1.axis('off')\n",
    "                ax2.imshow(y[0,:,:].cpu().detach().numpy(),cmap=cmap)\n",
    "                ax2.set_title('Targets')\n",
    "                ax2.axis('off')\n",
    "                ax3.imshow(preds_b[0,:,:].cpu().detach().numpy(),cmap = cmap)\n",
    "                ax3.set_title(f'Baseline, IoU: {curr_b:.3}')\n",
    "                ax3.axis('off')\n",
    "                ax4.imshow(preds_CE[0,:,:].cpu().detach().numpy(),cmap = cmap)\n",
    "                ax4.set_title(f'Pix2Pix CE, IoU: {curr_CE:.3}')\n",
    "                ax4.axis('off')\n",
    "                ax5.imshow(preds_FL[0,:,:].cpu().detach().numpy(),cmap = cmap)\n",
    "                ax5.set_title(f'Pix2Pix FL, IoU: {curr_FL:.3}')\n",
    "                ax5.axis('off')\n",
    "                plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-21T15:04:19.619041Z",
     "iopub.status.busy": "2023-12-21T15:04:19.618684Z",
     "iopub.status.idle": "2023-12-21T15:04:35.612616Z",
     "shell.execute_reply": "2023-12-21T15:04:35.611706Z",
     "shell.execute_reply.started": "2023-12-21T15:04:19.619014Z"
    }
   },
   "outputs": [],
   "source": [
    "# Check accuracy on the test data with Unet model trained on only real data\n",
    "check_accuracy(test_loader,baseline=model_only_real,P2P_CE=g_CE,P2P_FL=g_FL,plot=True) # set plot=True to see the predictions"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 4112789,
     "sourceId": 7128904,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4204317,
     "sourceId": 7255494,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30627,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
